"""
============================================================
VERSION 4.0 - APPLICATION ROUGEOLE COMPL√àTE
Garde toutes les fonctionnalit√©s + modules partag√©s
============================================================
"""

# ============================================================
# IMPORTS
# ============================================================
import streamlit as st
import pandas as pd
import numpy as np
import geopandas as gpd
from datetime import datetime, timedelta
import requests
from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor
from sklearn.linear_model import Ridge, Lasso
from sklearn.tree import DecisionTreeRegressor
from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler
from sklearn.model_selection import train_test_split, cross_val_score
import json
import folium
from folium.plugins import HeatMap, MarkerCluster
from streamlit_folium import st_folium
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from io import BytesIO
import zipfile
import tempfile
import os
from shapely.geometry import shape
import warnings
import sys

warnings.filterwarnings('ignore')

# Ajouter le dossier modules au path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'modules'))

# Imports des modules partag√©s
try:
    from modules.ui_components import apply_msf_branding, msf_header, msf_footer
    from modules.data_loader import DataManager
    from modules.geo_loader import GeoLoader
    from modules.climate_loader import ClimateLoader
    from modules.worldpop_loader import WorldPopLoader
    from modules.utils import safe_int, safe_float, format_large_number
    MODULES_AVAILABLE = True
except ImportError:
    MODULES_AVAILABLE = False
    st.warning("‚ö†Ô∏è Modules partag√©s non disponibles. Fonctionnement en mode autonome.")

# ============================================================
# APPLIQUER LE BRANDING MSF
# ============================================================
if MODULES_AVAILABLE:
    apply_msf_branding()
else:
    st.markdown("""
    <style>
        .main-header {
            font-size: 2.5rem;
            color: #E4032E;
            font-weight: bold;
            text-align: center;
            padding: 1rem;
        }
    </style>
    """, unsafe_allow_html=True)

# CSS sp√©cifique √† l'app Rougeole
st.markdown("""
<style>
    .high-risk {
        background-color: #ffebee;
        color: #c62828;
        font-weight: bold;
        padding: 5px;
        border-radius: 3px;
    }
    
    .medium-risk {
        background-color: #fff3e0;
        color: #ef6c00;
        padding: 5px;
        border-radius: 3px;
    }
    
    .low-risk {
        background-color: #e8f5e9;
        color: #2e7d32;
        padding: 5px;
        border-radius: 3px;
    }
    
    .model-hint {
        background-color: #fff9c4;
        padding: 8px;
        border-radius: 5px;
        font-size: 0.9em;
        margin: 5px 0;
    }
    
    .weight-box {
        background-color: #e8f5e9;
        padding: 10px;
        border-radius: 5px;
        margin: 10px 0;
        border-left: 4px solid #4caf50;
    }
</style>
""", unsafe_allow_html=True)

# ============================================================
# HEADER
# ============================================================
if MODULES_AVAILABLE:
    msf_header(
        "ü¶† Dashboard de Surveillance et Pr√©diction - Rougeole",
        "Analyse √©pid√©miologique et mod√©lisation pr√©dictive par semaines √©pid√©miologiques"
    )
else:
    st.markdown('<h1 class="main-header">ü¶† Dashboard de Surveillance et Pr√©diction - Rougeole</h1>', unsafe_allow_html=True)
    st.markdown("**Analyse √©pid√©miologique et mod√©lisation pr√©dictive par semaines √©pid√©miologiques**")

# ============================================================
# MAPPING PAYS (UNIFI√â)
# ============================================================
PAYS_ISO3_MAP = {
    "Niger": "ner",
    "Burkina Faso": "bfa",
    "Mali": "mli",
    "Mauritanie": "mrt"
}

# ============================================================
# INITIALISATION DU GESTIONNAIRE DE DONN√âES
# ============================================================
if MODULES_AVAILABLE:
    if 'data_manager' not in st.session_state:
        st.session_state.data_manager = DataManager()
    dm = st.session_state.data_manager
else:
    dm = None

# ============================================================
# INITIALISATION SESSION STATE
# ============================================================
if 'pays_precedent' not in st.session_state:
    st.session_state.pays_precedent = None
if 'sa_gdf_cache' not in st.session_state:
    st.session_state.sa_gdf_cache = None

# ============================================================
# FONCTIONS UTILITAIRES
# ============================================================

def safe_int(value):
    """Convertit en int en g√©rant les NaN"""
    if pd.isna(value) or value is None:
        return 0
    try:
        return int(value)
    except (ValueError, TypeError):
        return 0

def safe_float(value, default=0.0):
    """Convertit en float en g√©rant les NaN"""
    if pd.isna(value) or value is None:
        return default
    try:
        return float(value)
    except (ValueError, TypeError):
        return default

def normalize_colonnes(dataframe, mapping):
    """Renommer les colonnes du dataframe selon le mapping standardis√©"""
    rename_dict = {}
    for col_standard, col_possibles in mapping.items():
        for col_possible in col_possibles:
            if col_possible in dataframe.columns and col_possible != col_standard:
                rename_dict[col_possible] = col_standard
                break
    if rename_dict:
        dataframe = dataframe.rename(columns=rename_dict)
    return dataframe

def generate_dummy_linelists(sa_gdf, n=500, start=None, end=None):
    """G√©n√®re des donn√©es fictives de rougeole"""
    np.random.seed(42)
    
    if start is None:
        start = datetime(2024, 1, 1)
    if end is None:
        end = datetime.today()
    
    delta_days = (end - start).days
    
    dates = pd.to_datetime(start) + pd.to_timedelta(
        np.random.exponential(scale=delta_days/3, size=n).clip(0, delta_days).astype(int),
        unit='D'
    )
    
    df = pd.DataFrame({
        'ID_Cas': range(1, n+1),
        'Date_Debut_Eruption': dates,
        'Date_Notification': dates + pd.to_timedelta(np.random.poisson(3, n), unit='D'),
        'Aire_Sante': np.random.choice(sa_gdf['health_area'].unique(), n),
        'Age_Mois': np.random.gamma(shape=2, scale=30, size=n).clip(6, 180).astype(int),
        'Statut_Vaccinal': np.random.choice(['Oui', 'Non'], n, p=[0.55, 0.45]),
        'Sexe': np.random.choice(['M', 'F'], n),
        'Issue': np.random.choice(['Gu√©ri', 'D√©c√©d√©', 'Inconnu'], n, p=[0.92, 0.03, 0.05])
    })
    
    return df

def generate_dummy_vaccination(sa_gdf):
    """G√©n√®re des donn√©es fictives de vaccination"""
    np.random.seed(42)
    return pd.DataFrame({
        'health_area': sa_gdf['health_area'],
        'Taux_Vaccination': np.random.beta(a=8, b=2, size=len(sa_gdf)) * 100
    })

# ============================================================
# SIDEBAR - CONFIGURATION
# ============================================================

st.sidebar.header("üìÇ Configuration de l'Analyse")

# ============================================================
# Section 1 : Mode d'utilisation
# ============================================================
st.sidebar.subheader("üéØ Mode d'utilisation")
mode_demo = st.sidebar.radio(
    "Choisissez votre mode",
    ["üìä Donn√©es r√©elles", "üß™ Mode d√©mo (donn√©es simul√©es)"],
    help="Mode d√©mo : g√©n√®re automatiquement des donn√©es fictives pour tester l'application"
)

# ============================================================
# Section 2 : Aires de sant√© (UNIFI√â)
# ============================================================
st.sidebar.subheader("üó∫Ô∏è Aires de Sant√©")

sa_gdf = None

# V√©rifier si des donn√©es g√©ographiques sont d√©j√† charg√©es via DataManager
if MODULES_AVAILABLE and dm and dm.has_geodata():
    gdf_info = GeoLoader.get_geodata_info(dm.get_geodata())
    st.sidebar.success(f"‚úÖ {gdf_info['n_features']} aires charg√©es (r√©utilis√©es)")
    
    if st.sidebar.button("üîÑ Recharger de nouvelles aires"):
        dm.clear_by_type('geodata')
        st.session_state.sa_gdf_cache = None
        st.rerun()
    
    sa_gdf = dm.get_geodata()

else:
    option_aire = st.sidebar.radio(
        "Source des donn√©es g√©ographiques",
        ["Fichier local (ao_hlthArea.zip)", "Upload personnalis√©"],
        key='option_aire_rougeole'
    )
    
    pays_selectionne = None
    iso3_pays = None
    
    # OPTION 1 : Fichier local
    if option_aire == "Fichier local (ao_hlthArea.zip)":
        pays_selectionne = st.sidebar.selectbox(
            "üåç S√©lectionner le pays",
            list(PAYS_ISO3_MAP.keys()),
            key='pays_select_rougeole'
        )
        
        iso3_pays = PAYS_ISO3_MAP[pays_selectionne]
        
        # V√©rifier si changement de pays
        pays_change = st.session_state.pays_precedent != pays_selectionne
        
        if pays_change:
            st.session_state.pays_precedent = pays_selectionne
            st.session_state.sa_gdf_cache = None
        
        # Utiliser le cache si disponible
        if st.session_state.sa_gdf_cache is not None and not pays_change:
            sa_gdf = st.session_state.sa_gdf_cache
            st.sidebar.success(f"‚úÖ {len(sa_gdf)} aires de sant√© charg√©es (cache)")
        else:
            if st.sidebar.button("üì• Charger les aires") or pays_change:
                with st.spinner(f"‚è≥ Chargement des aires de {pays_selectionne}..."):
                    if MODULES_AVAILABLE:
                        sa_gdf = GeoLoader.load_local_ao_hltharea(iso3_pays)
                    else:
                        # Fallback sans modules
                        try:
                            zip_path = os.path.join("data", "ao_hlthArea.zip")
                            if not os.path.exists(zip_path):
                                zip_path = "ao_hlthArea.zip"
                            
                            with tempfile.TemporaryDirectory() as tmpdir:
                                with zipfile.ZipFile(zip_path, 'r') as z:
                                    z.extractall(tmpdir)
                                shp_files = [f for f in os.listdir(tmpdir) if f.endswith('.shp')]
                                if shp_files:
                                    gdf_full = gpd.read_file(os.path.join(tmpdir, shp_files[0]))
                                    
                                    # Filtrer par iso3
                                    iso3_col = None
                                    for col in ['iso3', 'ISO3', 'iso_code', 'ISOCODE']:
                                        if col in gdf_full.columns:
                                            iso3_col = col
                                            break
                                    
                                    if iso3_col:
                                        sa_gdf = gdf_full[gdf_full[iso3_col].str.lower() == iso3_pays.lower()].copy()
                                    else:
                                        sa_gdf = gdf_full
                        except Exception as e:
                            st.sidebar.error(f"‚ùå Erreur : {e}")
                            sa_gdf = None
                    
                    if sa_gdf is not None and not sa_gdf.empty:
                        # Normaliser health_area
                        if 'health_area' not in sa_gdf.columns:
                            for col in ['healtharea', 'HEALTHAREA', 'name_fr', 'NAME', 'nom', 'NOM', 'aire_sante']:
                                if col in sa_gdf.columns:
                                    sa_gdf['health_area'] = sa_gdf[col]
                                    break
                        
                        # Valider g√©om√©trie
                        sa_gdf = sa_gdf[sa_gdf.geometry.is_valid].copy()
                        
                        # WGS84
                        if sa_gdf.crs is None:
                            sa_gdf.set_crs('EPSG:4326', inplace=True)
                        elif sa_gdf.crs.to_epsg() != 4326:
                            sa_gdf = sa_gdf.to_crs('EPSG:4326')
                        
                        st.session_state.sa_gdf_cache = sa_gdf
                        
                        if MODULES_AVAILABLE and dm:
                            dm.set_geodata(sa_gdf, source=f"local_{iso3_pays}")
                        
                        st.sidebar.success(f"‚úÖ {len(sa_gdf)} aires de sant√© charg√©es")
                    else:
                        st.sidebar.error(f"‚ùå Impossible de charger les donn√©es pour {pays_selectionne}")
    
    # OPTION 2 : Upload personnalis√©
    else:
        upload_file = st.sidebar.file_uploader(
            "Charger un fichier g√©ographique",
            type=["shp", "geojson", "zip"],
            help="Format : Shapefile ou GeoJSON avec colonnes 'iso3' et 'health_area'",
            key='upload_geo_rougeole'
        )
        
        if upload_file is not None:
            if MODULES_AVAILABLE:
                sa_gdf = GeoLoader.load_from_file(upload_file)
            else:
                # Fallback sans modules
                try:
                    if upload_file.name.endswith('.geojson'):
                        sa_gdf = gpd.read_file(upload_file)
                    elif upload_file.name.endswith('.zip'):
                        with tempfile.TemporaryDirectory() as tmpdir:
                            zip_path = os.path.join(tmpdir, 'upload.zip')
                            with open(zip_path, 'wb') as f:
                                f.write(upload_file.getvalue())
                            
                            with zipfile.ZipFile(zip_path, 'r') as z:
                                z.extractall(tmpdir)
                            
                            shp_files = [f for f in os.listdir(tmpdir) if f.endswith('.shp')]
                            if shp_files:
                                sa_gdf = gpd.read_file(os.path.join(tmpdir, shp_files[0]))
                except Exception as e:
                    st.sidebar.error(f"‚ùå Erreur : {e}")
                    sa_gdf = None
            
            if sa_gdf is not None:
                # Normaliser
                if 'health_area' not in sa_gdf.columns:
                    for col in ['healtharea', 'HEALTHAREA', 'name_fr', 'NAME', 'nom']:
                        if col in sa_gdf.columns:
                            sa_gdf['health_area'] = sa_gdf[col]
                            break
                
                # WGS84
                if sa_gdf.crs is None:
                    sa_gdf.set_crs('EPSG:4326', inplace=True)
                elif sa_gdf.crs.to_epsg() != 4326:
                    sa_gdf = sa_gdf.to_crs('EPSG:4326')
                
                if MODULES_AVAILABLE and dm:
                    dm.set_geodata(sa_gdf, source="upload")
                
                st.sidebar.success(f"‚úÖ {len(sa_gdf)} aires de sant√© charg√©es")
        else:
            st.sidebar.info("üëÜ Uploadez un fichier pour commencer")

if sa_gdf is None or sa_gdf.empty:
    st.error("‚ùå Aucune aire de sant√© charg√©e. Configurez dans la sidebar.")
    st.stop()

# ============================================================
# Section 3 : Donn√©es √©pid√©miologiques
# ============================================================
st.sidebar.subheader("üìä Donn√©es √âpid√©miologiques")

df = None
vaccination_df = None

if mode_demo == "üß™ Mode d√©mo (donn√©es simul√©es)":
    linelist_file = None
    vaccination_file = None
    st.sidebar.info("üìä Mode d√©mo activ√© - Donn√©es simul√©es")
else:
    # V√©rifier si d√©j√† charg√©es
    if MODULES_AVAILABLE and dm and dm.has_epidemio_data('rougeole'):
        epidemio_info = dm.get_summary()['source_info'].get('epidemio_rougeole', {})
        st.sidebar.success(f"‚úÖ {epidemio_info.get('n_records', 0)} cas (r√©utilis√©s)")
        
        if st.sidebar.button("üîÑ Recharger les donn√©es rougeole"):
            dm.clear_by_type('epidemio')
            st.rerun()
        
        df = dm.get_epidemio_data('rougeole')
    
    else:
        linelist_file = st.sidebar.file_uploader(
            "üìã Linelists rougeole (CSV)",
            type=["csv"],
            help="Format : health_area, Semaine_Epi, Cas_Total OU Date_Debut_Eruption, Aire_Sante...",
            key='upload_cases_rougeole'
        )
    
    # Vaccination
    if MODULES_AVAILABLE and dm and dm.has_vaccination_data():
        st.sidebar.success("‚úÖ Couverture vaccinale (r√©utilis√©e)")
        vaccination_df = dm.get_vaccination_data()
    else:
        vaccination_file = st.sidebar.file_uploader(
            "üíâ Couverture vaccinale (CSV - optionnel)",
            type=["csv"],
            help="Format : health_area, Taux_Vaccination (en %)",
            key='upload_vacc_rougeole'
        )

# ============================================================
# Section 4 : P√©riode d'analyse
# ============================================================
st.sidebar.subheader("üìÖ P√©riode d'Analyse")

col1, col2 = st.sidebar.columns(2)

with col1:
    start_date = st.date_input(
        "Date d√©but",
        value=datetime(2024, 1, 1),
        key='start_date_rougeole'
    )

with col2:
    end_date = st.date_input(
        "Date fin",
        value=datetime.today(),
        key='end_date_rougeole'
    )

# ============================================================
# Section 5 : Param√®tres de pr√©diction
# ============================================================
st.sidebar.subheader("üîÆ Param√®tres de Pr√©diction")

pred_mois = st.sidebar.slider(
    "P√©riode de pr√©diction (mois)",
    min_value=1,
    max_value=12,
    value=3,
    help="Nombre de mois √† pr√©dire apr√®s la derni√®re semaine de donn√©es"
)

n_weeks_pred = pred_mois * 4
st.sidebar.info(f"üìÜ Pr√©diction sur **{n_weeks_pred} semaines √©pid√©miologiques** (~{pred_mois} mois)")

# ============================================================
# Section 6 : Choix du mod√®le
# ============================================================
st.sidebar.subheader("ü§ñ Mod√®le de Pr√©diction")

modele_choisi = st.sidebar.selectbox(
    "Choisissez votre algorithme",
    [
        "GradientBoosting (Recommand√©)",
        "RandomForest",
        "Ridge Regression",
        "Lasso Regression",
        "Decision Tree"
    ],
    help="S√©lectionnez l'algorithme de machine learning pour la pr√©diction"
)

# Hints pour chaque mod√®le
model_hints = {
    "GradientBoosting (Recommand√©)": "üéØ **Gradient Boosting** : Tr√®s performant pour les s√©ries temporelles. Combine plusieurs mod√®les faibles pour cr√©er un mod√®le fort. Excellent pour capturer les relations non-lin√©aires. Recommand√© pour la surveillance √©pid√©miologique.",
    "RandomForest": "üå≥ **Random Forest** : Ensemble d'arbres de d√©cision. Robuste aux valeurs aberrantes et aux donn√©es manquantes. Bon pour les interactions complexes entre variables.",
    "Ridge Regression": "üìä **Ridge Regression** : R√©gression lin√©aire avec r√©gularisation L2. Simple et rapide. Id√©al pour relations lin√©aires. Moins performant sur donn√©es non-lin√©aires.",
    "Lasso Regression": "üéØ **Lasso Regression** : R√©gularisation L1 avec s√©lection automatique des variables. Utile quand beaucoup de variables peu importantes. Simplifie le mod√®le.",
    "Decision Tree": "üå≤ **Decision Tree** : Arbre de d√©cision unique. Simple √† interpr√©ter mais risque de sur-apprentissage. Moins robuste que les m√©thodes d'ensemble."
}

st.sidebar.markdown(f'<div class="model-hint">{model_hints[modele_choisi]}</div>', unsafe_allow_html=True)

# ============================================================
# Section 7 : Importance des variables (CONSERV√â)
# ============================================================
st.sidebar.subheader("‚öñÔ∏è Importance des Variables")

mode_importance = st.sidebar.radio(
    "Mode de pond√©ration",
    ["Automatique (ML)", "Manuel (Expert)"],
    help="Automatique : calcul par le mod√®le ML | Manuel : poids d√©finis par expertise √©pid√©miologique"
)

poids_manuels = {}
poids_normalises = {}

if mode_importance == "Manuel (Expert)":
    with st.sidebar.expander("‚öôÔ∏è Configurer les poids", expanded=True):
        st.markdown("D√©finissez l'importance de chaque groupe de variables")
        st.caption("Les poids seront automatiquement normalis√©s pour totaliser 100%")
        
        poids_manuels['Historique_Cas'] = st.slider(
            "üìà Historique des cas (lags)",
            min_value=0, max_value=100, value=40, step=5,
            help="Importance des cas pass√©s (4 derni√®res semaines)"
        )
        
        poids_manuels['Vaccination'] = st.slider(
            "üíâ Couverture vaccinale",
            min_value=0, max_value=100, value=35, step=5,
            help="Importance du taux de vaccination et non-vaccin√©s"
        )
        
        poids_manuels['Demographie'] = st.slider(
            "üë• D√©mographie",
            min_value=0, max_value=100, value=15, step=5,
            help="Importance de la population et densit√©"
        )
        
        poids_manuels['Urbanisation'] = st.slider(
            "üèôÔ∏è Urbanisation",
            min_value=0, max_value=100, value=8, step=2,
            help="Importance du type d'habitat (urbain/rural)"
        )
        
        poids_manuels['Climat'] = st.slider(
            "üå°Ô∏è Facteurs climatiques",
            min_value=0, max_value=100, value=2, step=1,
            help="Importance de la temp√©rature, humidit√©, saison"
        )
        
        # Normaliser
        total_poids = sum(poids_manuels.values())
        if total_poids > 0:
            for key in poids_manuels:
                poids_normalises[key] = poids_manuels[key] / total_poids
        
        st.markdown("---")
        st.markdown("**R√©partition normalis√©e:**")
        for key, value in poids_normalises.items():
            st.markdown(f"- {key}: {value*100:.1f}%")
        
        if abs(total_poids - 100) > 5:
            st.info(f"üí° Total brut: {total_poids}% ‚Üí Normalis√©: 100%")
else:
    st.sidebar.info("Le mod√®le ML calculera automatiquement l'importance optimale de chaque variable")

# ============================================================
# Section 8 : Seuils d'alerte
# ============================================================
st.sidebar.subheader("üö® Seuils d'Alerte")

with st.sidebar.expander("‚öôÔ∏è Configurer les seuils", expanded=False):
    seuil_baisse = st.slider(
        "üìâ Seuil de baisse significative (%)",
        min_value=10, max_value=90, value=75, step=5,
        help="Afficher les aires avec baisse >= X% par rapport √† la moyenne"
    )
    
    seuil_hausse = st.slider(
        "üìà Seuil de hausse significative (%)",
        min_value=10, max_value=200, value=50, step=10,
        help="Afficher les aires avec hausse >= X% par rapport √† la moyenne"
    )
    
    seuil_alerte_epidemique = st.number_input(
        "‚ö†Ô∏è Seuil d'alerte √©pid√©mique (cas/semaine)",
        min_value=1, max_value=100, value=5,
        help="Nombre de cas par semaine d√©clenchant une alerte"
    )

# ============================================================
# CHARGEMENT DES DONN√âES
# ============================================================

st.markdown("---")
st.header("üì• Chargement des Donn√©es")

with st.spinner("‚è≥ Chargement des donn√©es de cas..."):
    
    if mode_demo == "üß™ Mode d√©mo (donn√©es simul√©es)":
        df = generate_dummy_linelists(sa_gdf, n=500, start=start_date, end=end_date)
        vaccination_df = generate_dummy_vaccination(sa_gdf)
        st.sidebar.info(f"‚úÖ {len(df)} cas simul√©s g√©n√©r√©s")
    
    else:
        # Chargement des donn√©es r√©elles
        if not MODULES_AVAILABLE or not dm or not dm.has_epidemio_data('rougeole'):
            if linelist_file is not None:
                try:
                    df_raw = pd.read_csv(linelist_file)
                    
                    # MAPPING DES COLONNES
                    COLONNES_MAPPING = {
                        'Aire_Sante': ['Aire_Sante', 'aire_sante', 'health_area', 'HEALTHAREA', 'name_fr', 'NAME', 'nom', 'NOM'],
                        'Date_Debut_Eruption': ['Date_Debut_Eruption', 'datedebuteruption', 'DateDebut', 'dateonset', 'DateOnset', 'symptom_onset'],
                        'Date_Notification': ['Date_Notification', 'datenotification', 'DateNotif', 'datenotif', 'notification_date'],
                        'ID_Cas': ['ID_Cas', 'idcas', 'ID', 'id', 'CaseID', 'caseid'],
                        'Age_Mois': ['Age_Mois', 'agemois', 'Age', 'age', 'AGE', 'AgeMonths', 'age_months'],
                        'Statut_Vaccinal': ['Statut_Vaccinal', 'statutvaccinal', 'Vaccin', 'vaccin', 'VaccinationStatus', 'vaccination_status'],
                        'Sexe': ['Sexe', 'sexe', 'Sex', 'sex', 'Gender', 'gender'],
                        'Issue': ['Issue', 'issue', 'Outcome', 'outcome', 'OUTCOME']
                    }
                    
                    # Format agr√©g√© ou linelist ?
                    if 'Semaine_Epi' in df_raw.columns and 'Cas_Total' in df_raw.columns:
                        # Format agr√©g√© ‚Üí d√©sagr√©ger
                        expanded_rows = []
                        
                        for _, row in df_raw.iterrows():
                            # Trouver colonne aire
                            aire = None
                            for col in ['health_area', 'Aire_Sante', 'name_fr', 'NAME']:
                                if col in row and not pd.isna(row.get(col)):
                                    aire = row[col]
                                    break
                            
                            semaine = int(row['Semaine_Epi'])
                            cas_total = int(row['Cas_Total'])
                            annee = row.get('Annee', 2024)
                            
                            base_date = datetime.strptime(f'{annee}-W{semaine:02d}-1', "%Y-W%W-%w")
                            
                            for i in range(cas_total):
                                expanded_rows.append({
                                    'ID_Cas': len(expanded_rows) + 1,
                                    'Date_Debut_Eruption': base_date + timedelta(days=np.random.randint(0, 7)),
                                    'Date_Notification': base_date + timedelta(days=np.random.randint(0, 10)),
                                    'Aire_Sante': aire,
                                    'Age_Mois': 0,
                                    'Statut_Vaccinal': 'Inconnu',
                                    'Sexe': 'Inconnu',
                                    'Issue': 'Inconnu'
                                })
                        
                        df = pd.DataFrame(expanded_rows)
                    
                    elif 'Date_Debut_Eruption' in df_raw.columns or any(col in df_raw.columns for col in COLONNES_MAPPING['Date_Debut_Eruption']):
                        # Format linelist
                        df = normalize_colonnes(df_raw, COLONNES_MAPPING)
                        
                        # Convertir dates
                        for col in ['Date_Debut_Eruption', 'Date_Notification']:
                            if col in df.columns:
                                df[col] = pd.to_datetime(df[col], errors='coerce')
                    
                    else:
                        st.error("‚ùå Format CSV non reconnu")
                        st.info(f"üìã Colonnes d√©tect√©es : {', '.join(df_raw.columns)}")
                        st.stop()
                    
                    if MODULES_AVAILABLE and dm:
                        dm.set_epidemio_data(df, disease='rougeole')
                    
                    st.sidebar.success(f"‚úÖ {len(df)} cas charg√©s")
                    
                except Exception as e:
                    st.error(f"‚ùå Erreur CSV : {e}")
                    st.stop()
            else:
                st.error("‚ùå Veuillez uploader un fichier CSV de lineliste")
                st.stop()
        
        # Vaccination
        if not MODULES_AVAILABLE or not dm or not dm.has_vaccination_data():
            if vaccination_file is not None:
                try:
                    vaccination_df = pd.read_csv(vaccination_file)
                    
                    # Normaliser
                    if 'health_area' not in vaccination_df.columns:
                        for col in ['Aire_Sante', 'aire_sante', 'name_fr']:
                            if col in vaccination_df.columns:
                                vaccination_df['health_area'] = vaccination_df[col]
                                break
                    
                    if MODULES_AVAILABLE and dm:
                        dm.set_vaccination_data(vaccination_df)
                    
                    st.sidebar.success(f"‚úÖ Couverture vaccinale charg√©e ({len(vaccination_df)} aires)")
                except Exception as e:
                    st.sidebar.warning(f"‚ö†Ô∏è Erreur vaccination CSV : {e}")
                    vaccination_df = None
            else:
                # Extraire de la linelist si disponible
                if df is not None and 'Statut_Vaccinal' in df.columns:
                    vacc_by_area = df.groupby('Aire_Sante').agg({
                        'Statut_Vaccinal': lambda x: (x == 'Oui').sum() / len(x) * 100 if len(x) > 0 else 0
                    }).reset_index()
                    
                    vacc_by_area.columns = ['health_area', 'Taux_Vaccination']
                    vaccination_df = vacc_by_area
                    st.sidebar.info("üíâ Taux vaccination extrait de la linelist")
                else:
                    vaccination_df = None
                    st.sidebar.info("‚ÑπÔ∏è Pas de donn√©es de vaccination")

# Normalisation finale des colonnes
if df is not None:
    if 'Aire_Sante' in df.columns and 'health_area' not in df.columns:
        df['health_area'] = df['Aire_Sante']
    
    if 'Date_Debut_Eruption' in df.columns:
        df['Date_Debut_Eruption'] = pd.to_datetime(df['Date_Debut_Eruption'], errors='coerce')
    
    # Filtrer par p√©riode
    df = df[
        (df['Date_Debut_Eruption'] >= pd.to_datetime(start_date)) &
        (df['Date_Debut_Eruption'] <= pd.to_datetime(end_date))
    ].copy()
    
    if len(df) == 0:
        st.warning("‚ö†Ô∏è Aucun cas dans la p√©riode s√©lectionn√©e")
        st.stop()
    
    # Ajouter semaine √©pid√©miologique
    df['Semaine_Epi'] = df['Date_Debut_Eruption'].dt.isocalendar().week
    df['Annee'] = df['Date_Debut_Eruption'].dt.year

# ============================================================
# AFFICHAGE DES STATISTIQUES G√âN√âRALES
# ============================================================

st.markdown("---")
st.header("üìä Vue d'Ensemble")

col1, col2, col3, col4 = st.columns(4)

with col1:
    st.metric("üó∫Ô∏è Aires de sant√©", len(sa_gdf))

with col2:
    st.metric("ü¶† Cas totaux", len(df))

with col3:
    n_weeks = df['Semaine_Epi'].nunique()
    st.metric("üìÖ Semaines", n_weeks)

with col4:
    if vaccination_df is not None:
        couv_moy = vaccination_df['Taux_Vaccination'].mean()
        st.metric("üíâ Couverture moy.", f"{couv_moy:.1f}%")
    else:
        st.metric("üíâ Couverture", "N/A")

# Afficher aper√ßu
with st.expander("üëÄ Aper√ßu des donn√©es"):
    st.dataframe(df.head(20))


# ============================================================
# SECTION CARTOGRAPHIE INTERACTIVE
# ============================================================

st.markdown("---")
st.header("üó∫Ô∏è Cartographie des Cas")

# Agr√©gation par aire de sant√©
cases_by_area = df.groupby('health_area').size().reset_index(name='cas_total')

# Fusion avec la g√©om√©trie
gdf_cases = sa_gdf.merge(cases_by_area, on='health_area', how='left')
gdf_cases['cas_total'] = gdf_cases['cas_total'].fillna(0)

# Fusion avec vaccination si disponible
if vaccination_df is not None:
    gdf_cases = gdf_cases.merge(vaccination_df[['health_area', 'Taux_Vaccination']], on='health_area', how='left')

# Cr√©er la carte
center_lat = gdf_cases.geometry.centroid.y.mean()
center_lon = gdf_cases.geometry.centroid.x.mean()

m = folium.Map(
    location=[center_lat, center_lon],
    zoom_start=6,
    tiles='CartoDB positron'
)

# Choropl√®the - Nombre de cas
folium.Choropleth(
    geo_data=gdf_cases,
    data=gdf_cases,
    columns=['health_area', 'cas_total'],
    key_on='feature.properties.health_area',
    fill_color='YlOrRd',
    fill_opacity=0.7,
    line_opacity=0.2,
    legend_name='Nombre de cas de rougeole',
    name='Cas de rougeole'
).add_to(m)

# Ajouter des popups enrichis
for idx, row in gdf_cases.iterrows():
    popup_html = f"""
    <div style="width:300px; font-family:Arial; font-size:12px;">
        <h4 style="color:#E4032E; margin:0;">{row['health_area']}</h4>
        <hr style="margin:5px 0;">
        <table style="width:100%;">
            <tr><td><b>ü¶† Cas:</b></td><td>{int(row['cas_total'])}</td></tr>
    """
    
    if 'Taux_Vaccination' in row and not pd.isna(row['Taux_Vaccination']):
        taux = row['Taux_Vaccination']
        color = '#4caf50' if taux >= 95 else ('#ff9800' if taux >= 80 else '#f44336')
        popup_html += f"<tr style='background:{color}20;'><td><b>üíâ Vaccination:</b></td><td>{taux:.1f}%</td></tr>"
    
    popup_html += """
        </table>
    </div>
    """
    
    # Taille du marker proportionnelle au nombre de cas
    radius = min(5 + row['cas_total'] / 5, 20)
    
    folium.CircleMarker(
        location=[row.geometry.centroid.y, row.geometry.centroid.x],
        radius=radius,
        popup=folium.Popup(popup_html, max_width=300),
        color='#E4032E',
        fill=True,
        fillColor='#E4032E',
        fillOpacity=0.6
    ).add_to(m)

# Si vaccination disponible, ajouter couche
if vaccination_df is not None:
    folium.Choropleth(
        geo_data=gdf_cases,
        data=gdf_cases,
        columns=['health_area', 'Taux_Vaccination'],
        key_on='feature.properties.health_area',
        fill_color='RdYlGn',
        fill_opacity=0.5,
        line_opacity=0.2,
        legend_name='Couverture vaccinale (%)',
        name='Couverture vaccinale',
        show=False
    ).add_to(m)

folium.LayerControl().add_to(m)

st_folium(m, width=1200, height=600, key='rougeole_map')

# L√©gende vaccination
if vaccination_df is not None:
    st.markdown("""
    <div style="background:#f0f2f6; padding:1rem; border-radius:8px; margin-top:1rem;">
        <b>üíâ L√©gende Couverture Vaccinale:</b><br>
        üü¢ ‚â•95% : Objectif OMS atteint (immunit√© collective)<br>
        üü° 80-94% : Insuffisant (risque flamb√©es localis√©es)<br>
        üî¥ <80% : Tr√®s insuffisant (risque √©pid√©mie majeure)
    </div>
    """, unsafe_allow_html=True)

# ============================================================
# SECTION ANALYSE TEMPORELLE ET √âPID√âMIOLOGIQUE
# ============================================================

st.markdown("---")
st.header("üìà Analyse √âpid√©miologique")

# Agr√©gation hebdomadaire
weekly_cases = df.groupby(['Annee', 'Semaine_Epi']).size().reset_index(name='cas')
weekly_cases['date'] = pd.to_datetime(
    weekly_cases['Annee'].astype(str) + '-W' + weekly_cases['Semaine_Epi'].astype(str).str.zfill(2) + '-1',
    format='%Y-W%W-%w'
)
weekly_cases = weekly_cases.sort_values('date')

# Calculer seuil √©pid√©mique (Moyenne + 2 SD)
mean_cases = weekly_cases['cas'].mean()
std_cases = weekly_cases['cas'].std()
seuil_epidemique_calc = mean_cases + 2 * std_cases

# Courbe √©pid√©mique
fig_epi = go.Figure()

fig_epi.add_trace(go.Scatter(
    x=weekly_cases['date'],
    y=weekly_cases['cas'],
    mode='lines+markers',
    name='Cas hebdomadaires',
    line=dict(color='#E4032E', width=2),
    marker=dict(size=6),
    fill='tozeroy',
    fillcolor='rgba(228, 3, 46, 0.1)'
))

# Ligne seuil √©pid√©mique
fig_epi.add_trace(go.Scatter(
    x=[weekly_cases['date'].min(), weekly_cases['date'].max()],
    y=[seuil_epidemique_calc, seuil_epidemique_calc],
    mode='lines',
    name=f'Seuil √©pid√©mique (M+2SD = {seuil_epidemique_calc:.0f})',
    line=dict(color='red', width=2, dash='dash')
))

# Ligne moyenne
fig_epi.add_trace(go.Scatter(
    x=[weekly_cases['date'].min(), weekly_cases['date'].max()],
    y=[mean_cases, mean_cases],
    mode='lines',
    name=f'Moyenne ({mean_cases:.0f})',
    line=dict(color='gray', width=1, dash='dot')
))

fig_epi.update_layout(
    title='Courbe √âpid√©mique - Rougeole',
    xaxis_title='Date (Semaine √©pid√©miologique)',
    yaxis_title='Nombre de cas',
    hovermode='x unified',
    height=400
)

st.plotly_chart(fig_epi, use_container_width=True)

# Alertes √©pid√©miques
semaines_alerte = weekly_cases[weekly_cases['cas'] > seuil_epidemique_calc]

if len(semaines_alerte) > 0:
    st.error(f"üö® **ALERTE √âPID√âMIQUE** : {len(semaines_alerte)} semaines au-dessus du seuil !")
    
    with st.expander("üìã D√©tails des semaines en alerte"):
        st.dataframe(semaines_alerte[['Annee', 'Semaine_Epi', 'cas', 'date']])
else:
    st.success("‚úÖ Aucune semaine au-dessus du seuil √©pid√©mique")

# Analyse par aire de sant√©
st.subheader("üìä Analyse par Aire de Sant√©")

col1, col2 = st.columns(2)

with col1:
    st.markdown("**üîù Top 10 Aires Touch√©es**")
    top10 = gdf_cases.nlargest(10, 'cas_total')[['health_area', 'cas_total']]
    
    if 'Taux_Vaccination' in gdf_cases.columns:
        top10 = gdf_cases.nlargest(10, 'cas_total')[['health_area', 'cas_total', 'Taux_Vaccination']]
    
    st.dataframe(top10, use_container_width=True)

with col2:
    st.markdown("**üìâ Distribution des Cas**")
    
    fig_dist = go.Figure()
    fig_dist.add_trace(go.Box(
        y=gdf_cases['cas_total'],
        name='Cas par aire',
        marker_color='#E4032E'
    ))
    
    fig_dist.update_layout(
        yaxis_title='Nombre de cas',
        height=250
    )
    
    st.plotly_chart(fig_dist, use_container_width=True)

# Analyse par √¢ge (si disponible)
if 'Age_Mois' in df.columns:
    st.subheader("üë∂ Distribution par √Çge")
    
    df_age = df[df['Age_Mois'] > 0].copy()
    df_age['Age_Annees'] = df_age['Age_Mois'] / 12
    df_age['Groupe_Age'] = pd.cut(
        df_age['Age_Annees'],
        bins=[0, 1, 5, 10, 15, 100],
        labels=['<1 an', '1-4 ans', '5-9 ans', '10-14 ans', '‚â•15 ans']
    )
    
    age_stats = df_age.groupby('Groupe_Age').size().reset_index(name='cas')
    
    fig_age = px.bar(
        age_stats,
        x='Groupe_Age',
        y='cas',
        title='Distribution des Cas par Groupe d\'√Çge',
        labels={'Groupe_Age': 'Groupe d\'√¢ge', 'cas': 'Nombre de cas'},
        color='cas',
        color_continuous_scale='Reds'
    )
    
    st.plotly_chart(fig_age, use_container_width=True)
    
    # Indicateurs enfants <5 ans
    enfants_5 = len(df_age[df_age['Age_Annees'] < 5])
    pct_enfants_5 = (enfants_5 / len(df_age)) * 100
    
    st.info(f"üë∂ **{enfants_5} cas ({pct_enfants_5:.1f}%)** chez les enfants < 5 ans")

# Analyse par statut vaccinal (si disponible)
if 'Statut_Vaccinal' in df.columns:
    st.subheader("üíâ Analyse par Statut Vaccinal")
    
    vacc_stats = df[df['Statut_Vaccinal'].isin(['Oui', 'Non'])].groupby('Statut_Vaccinal').size().reset_index(name='cas')
    
    fig_vacc = px.pie(
        vacc_stats,
        values='cas',
        names='Statut_Vaccinal',
        title='R√©partition par Statut Vaccinal',
        color='Statut_Vaccinal',
        color_discrete_map={'Oui': '#4caf50', 'Non': '#f44336'}
    )
    
    st.plotly_chart(fig_vacc, use_container_width=True)
    
    # Indicateur cl√©
    non_vaccines = vacc_stats[vacc_stats['Statut_Vaccinal'] == 'Non']['cas'].sum() if 'Non' in vacc_stats['Statut_Vaccinal'].values else 0
    total_connus = vacc_stats['cas'].sum()
    pct_non_vaccines = (non_vaccines / total_connus) * 100 if total_connus > 0 else 0
    
    if pct_non_vaccines > 50:
        st.error(f"‚ö†Ô∏è **{pct_non_vaccines:.1f}%** des cas chez les non-vaccin√©s ‚Üí √âchec vaccinal faible, probl√®me de couverture")
    else:
        st.warning(f"üí° **{pct_non_vaccines:.1f}%** des cas chez les non-vaccin√©s ‚Üí Possible √©chec vaccinal √† investiguer")

# ============================================================
# SECTION MOD√âLISATION PR√âDICTIVE (COMPL√àTE)
# ============================================================

st.markdown("---")
st.header("ü§ñ Mod√©lisation Pr√©dictive")

st.markdown("""
<div style="background:#f0f2f6; padding:1rem; border-radius:8px; border-left:4px solid #E4032E; margin:1rem 0;">
<b>Note:</b> La mod√©lisation n√©cessite au moins 8 semaines de donn√©es. Les variables de vaccination 
et d√©mographiques sont cruciales pour la rougeole (maladie √©vitable par vaccination).
</div>
""", unsafe_allow_html=True)

# V√©rifier conditions minimales
if n_weeks < 8:
    st.warning(f"‚ö†Ô∏è Nombre de semaines insuffisant ({n_weeks}/8 minimum). Ajoutez plus de donn√©es historiques.")
    st.stop()

# Bouton pour lancer la mod√©lisation
if st.button("üöÄ LANCER LA MOD√âLISATION", type="primary", use_container_width=True):
    
    with st.spinner("‚è≥ Pr√©paration des donn√©es et entra√Ænement du mod√®le..."):
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # √âtape 1: Pr√©paration des donn√©es (20%)
        status_text.text("üìä Pr√©paration des donn√©es hebdomadaires...")
        progress_bar.progress(0.2)
        
        # Cr√©er dataset hebdomadaire par aire
        weekly_data = []
        
        for area in sa_gdf['health_area'].unique():
            df_area = df[df['health_area'] == area]
            
            if len(df_area) == 0:
                continue
            
            # Agr√©ger par semaine
            area_weekly = df_area.groupby(['Annee', 'Semaine_Epi']).size().reset_index(name='Cas_Observes')
            
            for _, row in area_weekly.iterrows():
                week_label = f"{int(row['Annee'])}-S{int(row['Semaine_Epi']):02d}"
                
                weekly_data.append({
                    'health_area': area,
                    'Annee': int(row['Annee']),
                    'Semaine_Epi': int(row['Semaine_Epi']),
                    'SemLabel': week_label,
                    'Cas_Observes': int(row['Cas_Observes'])
                })
        
        weekly_features = pd.DataFrame(weekly_data)
        
        # Ajouter num√©ro de semaine global
        weekly_features['weeknum'] = weekly_features['Semaine_Epi']
        
        # √âtape 2: Cr√©ation des features (30%)
        status_text.text("üîß Cr√©ation des features temporelles...")
        progress_bar.progress(0.3)
        
        # Trier par aire et semaine
        weekly_features = weekly_features.sort_values(['health_area', 'weeknum'])
        
        # Lags
        for lag in [1, 2, 4]:
            weekly_features[f'CasLag{lag}'] = weekly_features.groupby('health_area')['Cas_Observes'].shift(lag)
        
        # Moyennes mobiles
        for window in [2, 4]:
            weekly_features[f'CasMA{window}'] = weekly_features.groupby('health_area')['Cas_Observes'].transform(
                lambda x: x.rolling(window, min_periods=1).mean()
            )
        
        # Taux de croissance
        weekly_features['GrowthRate'] = weekly_features.groupby('health_area')['Cas_Observes'].pct_change().fillna(0)
        
        # Features cycliques
        weekly_features['sin_week'] = np.sin(2 * np.pi * weekly_features['weeknum'] / 52)
        weekly_features['cos_week'] = np.cos(2 * np.pi * weekly_features['weeknum'] / 52)
        
        # √âtape 3: Ajouter vaccination (35%)
        if vaccination_df is not None:
            status_text.text("üíâ Ajout des donn√©es de vaccination...")
            progress_bar.progress(0.35)
            
            weekly_features = weekly_features.merge(
                vaccination_df[['health_area', 'Taux_Vaccination']],
                on='health_area',
                how='left'
            )
            
            # Features d√©riv√©es vaccination
            weekly_features['Non_Vaccines_Pct'] = 100 - weekly_features['Taux_Vaccination'].fillna(80)
            weekly_features['Susceptibles'] = weekly_features['Non_Vaccines_Pct'] / 100
        
        # √âtape 4: Ajouter d√©mographie si disponible (40%)
        if MODULES_AVAILABLE and dm and dm.has_worldpop_data():
            status_text.text("üë• Ajout des donn√©es d√©mographiques...")
            progress_bar.progress(0.4)
            
            df_worldpop = dm.get_worldpop_data()
            
            weekly_features = weekly_features.merge(
                df_worldpop[['health_area', 'Pop_Totale', 'Pop_Enfants_0_14', 'Densite_Pop']],
                on='health_area',
                how='left'
            )
        
        # √âtape 5: S√©lection des features (45%)
        status_text.text("üîç S√©lection des features...")
        progress_bar.progress(0.45)
        
        feature_cols = ['weeknum', 'sin_week', 'cos_week']
        
        # Lags
        for lag in [1, 2, 4]:
            if f'CasLag{lag}' in weekly_features.columns:
                feature_cols.append(f'CasLag{lag}')
        
        # Moyennes mobiles
        for window in [2, 4]:
            if f'CasMA{window}' in weekly_features.columns:
                feature_cols.append(f'CasMA{window}')
        
        # Growth rate
        if 'GrowthRate' in weekly_features.columns:
            feature_cols.append('GrowthRate')
        
        # Vaccination
        for col in ['Taux_Vaccination', 'Non_Vaccines_Pct', 'Susceptibles']:
            if col in weekly_features.columns:
                feature_cols.append(col)
        
        # D√©mographie
        for col in ['Pop_Totale', 'Pop_Enfants_0_14', 'Densite_Pop']:
            if col in weekly_features.columns:
                feature_cols.append(col)
        
        # Supprimer NaN
        df_model = weekly_features.dropna(subset=feature_cols + ['Cas_Observes'])
        
        st.info(f"üìä {len(df_model)} observations ‚Ä¢ {len(feature_cols)} features ‚Ä¢ {df_model['health_area'].nunique()} aires")
        
        # Afficher features
        with st.expander("üìã Features utilis√©es"):
            st.write(feature_cols)
        
        # √âtape 6: Mapping des poids manuels (si activ√©) (50%)
        column_weights = {}
        
        if mode_importance == "Manuel (Expert)" and poids_normalises:
            status_text.text("‚öñÔ∏è Application des poids manuels...")
            progress_bar.progress(0.5)
            
            # Mapper les features aux cat√©gories
            for col in feature_cols:
                if 'Lag' in col or 'MA' in col or 'Growth' in col:
                    column_weights[col] = poids_normalises.get('Historique_Cas', 1.0)
                elif 'Vacc' in col or 'Suscept' in col:
                    column_weights[col] = poids_normalises.get('Vaccination', 1.0)
                elif 'Pop' in col or 'Densite' in col:
                    column_weights[col] = poids_normalises.get('Demographie', 1.0)
                elif 'sin' in col or 'cos' in col:
                    column_weights[col] = poids_normalises.get('Climat', 1.0)
                else:
                    column_weights[col] = 1.0
            
            st.markdown("**Poids appliqu√©s:**")
            with st.expander("Voir les poids par feature"):
                for col, weight in column_weights.items():
                    st.markdown(f"- {col}: {weight:.3f}")
        
        # √âtape 7: Train/Test split (55%)
        status_text.text("üîÄ Split temporel des donn√©es...")
        progress_bar.progress(0.55)
        
        X = df_model[feature_cols]
        y = df_model['Cas_Observes']
        
        # Split 80/20
        split_idx = int(len(df_model) * 0.8)
        X_train, X_test = X[:split_idx], X[split_idx:]
        y_train, y_test = y[:split_idx], y[split_idx:]
        
        # √âtape 8: Normalisation (60%)
        status_text.text("üìê Normalisation...")
        progress_bar.progress(0.6)
        
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # Appliquer poids manuels si activ√©s
        if mode_importance == "Manuel (Expert)" and column_weights:
            for idx, col in enumerate(feature_cols):
                if col in column_weights:
                    X_train_scaled[:, idx] *= column_weights[col]
                    X_test_scaled[:, idx] *= column_weights[col]
        
        # √âtape 9: Entra√Ænement (70%)
        status_text.text("üß† Entra√Ænement du mod√®le...")
        progress_bar.progress(0.7)
        
        if modele_choisi == "GradientBoosting (Recommand√©)":
            model = GradientBoostingRegressor(
                n_estimators=100,
                learning_rate=0.1,
                max_depth=5,
                subsample=0.8,
                random_state=42
            )
        elif modele_choisi == "RandomForest":
            model = RandomForestRegressor(
                n_estimators=100,
                max_depth=10,
                random_state=42
            )
        elif modele_choisi == "Ridge Regression":
            model = Ridge(alpha=1.0)
        elif modele_choisi == "Lasso Regression":
            model = Lasso(alpha=0.1)
        else:
            model = DecisionTreeRegressor(max_depth=10, random_state=42)
        
        model.fit(X_train_scaled, y_train)
        
        # √âtape 10: Validation crois√©e (80%)
        status_text.text("‚úÖ Validation crois√©e...")
        progress_bar.progress(0.8)
        
        from sklearn.model_selection import TimeSeriesSplit
        tscv = TimeSeriesSplit(n_splits=5)
        cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=tscv, scoring='r2')
        cv_mean = cv_scores.mean()
        cv_std = cv_scores.std()
        
        # √âtape 11: √âvaluation (85%)
        status_text.text("üìä Calcul des m√©triques...")
        progress_bar.progress(0.85)
        
        y_pred_train = model.predict(X_train_scaled)
        y_pred_test = model.predict(X_test_scaled)
        
        from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
        
        r2_train = r2_score(y_train, y_pred_train)
        r2_test = r2_score(y_test, y_pred_test)
        mae_test = mean_absolute_error(y_test, y_pred_test)
        rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))
        
        # √âtape 12: Pr√©dictions futures (90%)
        status_text.text("üîÆ G√©n√©ration des pr√©dictions futures...")
        progress_bar.progress(0.9)
        
        last_week = df_model['weeknum'].max()
        future_predictions = []
        
        for area in df_model['health_area'].unique():
            df_area = df_model[df_model['health_area'] == area].tail(10)
            
            if len(df_area) == 0:
                continue
            
            # Features constantes
            constant_features = {}
            for col in ['Taux_Vaccination', 'Non_Vaccines_Pct', 'Susceptibles', 'Pop_Totale', 'Pop_Enfants_0_14', 'Densite_Pop']:
                if col in df_area.columns and col in feature_cols:
                    constant_features[col] = df_area[col].mean()
            
            # Pr√©dictions it√©ratives
            prev_predictions = list(df_area['Cas_Observes'].tail(4))
            
            for i in range(1, n_weeks_pred + 1):
                future_week = last_week + i
                
                future_row = {
                    'weeknum': future_week,
                    'sin_week': np.sin(2 * np.pi * (future_week / 52)),
                    'cos_week': np.cos(2 * np.pi * (future_week / 52))
                }
                
                # Lags
                future_row['CasLag1'] = prev_predictions[-1] if len(prev_predictions) > 0 else df_area['Cas_Observes'].mean()
                future_row['CasLag2'] = prev_predictions[-2] if len(prev_predictions) > 1 else df_area['Cas_Observes'].mean()
                future_row['CasLag4'] = prev_predictions[-4] if len(prev_predictions) > 3 else df_area['Cas_Observes'].mean()
                
                # MA
                future_row['CasMA2'] = np.mean(prev_predictions[-2:]) if len(prev_predictions) > 1 else df_area['Cas_Observes'].mean()
                future_row['CasMA4'] = np.mean(prev_predictions[-4:]) if len(prev_predictions) > 3 else df_area['Cas_Observes'].mean()
                
                # Growth
                if len(prev_predictions) > 1:
                    future_row['GrowthRate'] = (prev_predictions[-1] - prev_predictions[-2]) / (prev_predictions[-2] + 1)
                else:
                    future_row['GrowthRate'] = 0
                
                # Constantes
                for col, val in constant_features.items():
                    future_row[col] = val
                
                # Pr√©dire
                X_future = pd.DataFrame([future_row])[feature_cols]
                X_future_scaled = scaler.transform(X_future)
                
                # Appliquer poids manuels
                if mode_importance == "Manuel (Expert)" and column_weights:
                    for idx, col in enumerate(feature_cols):
                        if col in column_weights:
                            X_future_scaled[:, idx] *= column_weights[col]
                
                pred_cases = max(0, model.predict(X_future_scaled)[0])
                
                prev_predictions.append(pred_cases)
                
                future_predictions.append({
                    'health_area': area,
                    'SemainePic': f"S{int(future_week)}",
                    'PredictedCases': pred_cases
                })
        
        future_df = pd.DataFrame(future_predictions)
        
        progress_bar.progress(1.0)
        status_text.text("‚úÖ Mod√©lisation termin√©e !")
        
        # AFFICHAGE DES R√âSULTATS
        st.success("‚úÖ Mod√©lisation termin√©e !")
        
        # M√©triques
        st.subheader("üìä Performance du Mod√®le")
        
        col1, col2, col3, col4, col5 = st.columns(5)
        
        with col1:
            st.metric("R¬≤ Train", f"{r2_train:.3f}")
        
        with col2:
            st.metric("R¬≤ Test", f"{r2_test:.3f}")
        
        with col3:
            st.metric("R¬≤ CV", f"{cv_mean:.3f}")
        
        with col4:
            st.metric("MAE", f"{mae_test:.1f}")
        
        with col5:
            st.metric("RMSE", f"{rmse_test:.1f}")
        
        # Interpr√©tation
        if r2_test > 0.75:
            st.success("üéØ Excellent mod√®le ! R¬≤ > 0.75")
        elif r2_test > 0.55:
            st.info("üëç Bon mod√®le. R¬≤ > 0.55")
        else:
            st.warning("‚ö†Ô∏è Mod√®le √† am√©liorer. Ajoutez plus de donn√©es ou features.")
        
        # Graphique pr√©dictions vs observations
        st.subheader("üìà Pr√©dictions vs Observations")
        
        fig_pred = go.Figure()
        
        fig_pred.add_trace(go.Scatter(
            x=y_test.values,
            y=y_pred_test,
            mode='markers',
            name='Pr√©dictions',
            marker=dict(color='#E4032E', size=8, opacity=0.6)
        ))
        
        max_val = max(y_test.max(), y_pred_test.max())
        fig_pred.add_trace(go.Scatter(
            x=[0, max_val],
            y=[0, max_val],
            mode='lines',
            name='Pr√©diction parfaite',
            line=dict(color='gray', dash='dash')
        ))
        
        fig_pred.update_layout(
            xaxis_title='Cas observ√©s',
            yaxis_title='Cas pr√©dits',
            height=400
        )
        
        st.plotly_chart(fig_pred, use_container_width=True)
        
        # Importance des variables (si disponible)
        if hasattr(model, 'feature_importances_'):
            st.subheader("üîç Importance des Variables")
            
            feature_importance = pd.DataFrame({
                'Variable': feature_cols,
                'Importance': model.feature_importances_
            }).sort_values('Importance', ascending=False)
            
            fig_imp = px.bar(
                feature_importance.head(10),
                x='Importance',
                y='Variable',
                orientation='h',
                title='Top 10 Variables'
            )
            
            fig_imp.update_traces(marker_color='#E4032E')
            
            st.plotly_chart(fig_imp, use_container_width=True)
        
        # Pr√©dictions futures
        st.subheader(f"üîÆ Pr√©dictions ({n_weeks_pred} semaines)")
        
        # Analyse des risques
        moyenne_historique = weekly_features.groupby('health_area')['Cas_Observes'].mean().reset_index()
        moyenne_historique.columns = ['health_area', 'MoyenneHistorique']
        
        risk_df = future_df.groupby('health_area').agg({
            'PredictedCases': ['sum', 'max', 'mean'],
            'SemainePic': lambda x: future_df.loc[x.idxmax(), 'SemainePic'] if len(x) > 0 else 'NA'
        }).reset_index()
        
        risk_df.columns = ['health_area', 'CasPreditsTotal', 'CasPreditsMax', 'CasPreditsMoyen', 'SemainePic']
        
        risk_df = risk_df.merge(moyenne_historique, on='health_area', how='left')
        risk_df['VariationPct'] = ((risk_df['CasPreditsMoyen'] - risk_df['MoyenneHistorique']) / risk_df['MoyenneHistorique'].replace(0, 1)) * 100
        
        risk_df['CategorieVariation'] = pd.cut(
            risk_df['VariationPct'],
            bins=[-np.inf, -seuil_baisse, -10, 10, seuil_hausse, np.inf],
            labels=['Forte baisse', 'Baisse mod√©r√©e', 'Stable', 'Hausse mod√©r√©e', 'Forte hausse']
        )
        
        # Tableau de synth√®se avec alertes
        tab1, tab2, tab3 = st.tabs(["üö® Alertes Hausse", "üìâ Baisses", "üìã Tableau Complet"])
        
        with tab1:
            st.subheader(f"Aires avec Hausse Significative (‚â•{seuil_hausse}%)")
            
            hausse_df = risk_df[risk_df['VariationPct'] >= seuil_hausse].copy()
            
            if len(hausse_df) > 0:
                def highlight_hausse(row):
                    return ['background-color: #ffebee'] * len(row)
                
                st.dataframe(
                    hausse_df[['health_area', 'MoyenneHistorique', 'CasPreditsMoyen', 'VariationPct', 'SemainePic', 'CasPreditsMax']]
                    .style.apply(highlight_hausse, axis=1)
                    .format({
                        'MoyenneHistorique': '{:.1f}',
                        'CasPreditsMoyen': '{:.1f}',
                        'VariationPct': '{:.1f}%',
                        'CasPreditsMax': '{:.0f}'
                    }),
                    use_container_width=True
                )
                
                st.warning(f"‚ö†Ô∏è **{len(hausse_df)} aires** n√©cessitent une vigilance accrue")
            else:
                st.success("‚úÖ Aucune aire avec hausse significative")
        
        with tab2:
            st.subheader(f"Aires avec Baisse Significative (‚â•{seuil_baisse}%)")
            
            baisse_df = risk_df[risk_df['VariationPct'] <= -seuil_baisse].copy()
            
            if len(baisse_df) > 0:
                def highlight_baisse(row):
                    return ['background-color: #e8f5e9'] * len(row)
                
                st.dataframe(
                    baisse_df[['health_area', 'MoyenneHistorique', 'CasPreditsMoyen', 'VariationPct', 'SemainePic', 'CasPreditsMax']]
                    .style.apply(highlight_baisse, axis=1)
                    .format({
                        'MoyenneHistorique': '{:.1f}',
                        'CasPreditsMoyen': '{:.1f}',
                        'VariationPct': '{:.1f}%',
                        'CasPreditsMax': '{:.0f}'
                    }),
                    use_container_width=True
                )
                
                st.success(f"‚úÖ {len(baisse_df)} aires montrent une am√©lioration")
            else:
                st.info("‚ÑπÔ∏è Aucune aire avec baisse significative")
        
        with tab3:
            st.subheader("Tableau Complet des Pr√©dictions")
            st.dataframe(risk_df.sort_values('CasPreditsTotal', ascending=False), use_container_width=True)
        
        # Top 10 aires √† risque
        st.subheader("üéØ Top 10 Aires √† Risque (Pr√©dictions)")
        
        top_pred = risk_df.nlargest(10, 'CasPreditsTotal')
        
        fig_top = px.bar(
            top_pred,
            x='CasPreditsTotal',
            y='health_area',
            orientation='h',
            title=f'Cas Pr√©dits Totaux ({n_weeks_pred} semaines)',
            labels={'CasPreditsTotal': 'Cas pr√©dits', 'health_area': 'Aire de sant√©'}
        )
        
        fig_top.update_traces(marker_color='#E4032E')
        
        st.plotly_chart(fig_top, use_container_width=True)
        
        # EXPORTS
        st.subheader("üíæ T√©l√©chargements")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            csv = future_df.to_csv(index=False)
            st.download_button(
                label="üì• Pr√©dictions (CSV)",
                data=csv,
                file_name=f"predictions_rougeole_{datetime.now().strftime('%Y%m%d')}.csv",
                mime="text/csv",
                use_container_width=True
            )
        
        with col2:
            gdf_pred = sa_gdf.merge(
                risk_df[['health_area', 'CasPreditsTotal']],
                on='health_area',
                how='left'
            )
            
            geojson_str = gdf_pred.to_json()
            st.download_button(
                label="üó∫Ô∏è Carte (GeoJSON)",
                data=geojson_str,
                file_name=f"carte_predictions_rougeole_{datetime.now().strftime('%Y%m%d')}.geojson",
                mime="application/json",
                use_container_width=True
            )
        
        with col3:
            output = BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                # R√©sum√©
                summary_df = pd.DataFrame({
                    'M√©trique': ['R¬≤ Train', 'R¬≤ Test', 'R¬≤ CV', 'MAE', 'RMSE', 'Nb Features', 'Nb Observations'],
                    'Valeur': [r2_train, r2_test, cv_mean, mae_test, rmse_test, len(feature_cols), len(df_model)]
                })
                summary_df.to_excel(writer, sheet_name='R√©sum√©', index=False)
                
                # Pr√©dictions
                risk_df.to_excel(writer, sheet_name='Synth√®se', index=False)
                future_df.to_excel(writer, sheet_name='D√©tail Semaines', index=False)
                
                # Historique
                cases_by_area.to_excel(writer, sheet_name='Cas Observ√©s', index=False)
                
                # Stats √¢ge si disponible
                if 'Age_Mois' in df.columns:
                    df_age.groupby('Groupe_Age').size().reset_index(name='cas').to_excel(writer, sheet_name='Analyse √Çge', index=False)
                
                # Historique hebdo
                weekly_cases.to_excel(writer, sheet_name='Historique Hebdo', index=False)
            
            st.download_button(
                label="üìä Rapport Complet (Excel)",
                data=output.getvalue(),
                file_name=f"rapport_rougeole_{datetime.now().strftime('%Y%m%d')}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True
            )
        
        # Recommandations
        st.subheader("üí° Recommandations Op√©rationnelles")
        
        aires_critiques_hausse = risk_df[risk_df['VariationPct'] >= seuil_hausse]['health_area'].tolist()
        aires_amelioration = risk_df[risk_df['VariationPct'] <= -seuil_baisse]['health_area'].tolist()
        
        if aires_critiques_hausse:
            st.error(f"üö® **{len(aires_critiques_hausse)} aires √† risque CRITIQUE** (hausse ‚â•{seuil_hausse}%)")
            
            for i, aire in enumerate(aires_critiques_hausse[:5], 1):
                st.markdown(f"{i}. **{aire}** ‚Üí Intensifier surveillance + Envisager CVR")
        
        if aires_amelioration:
            st.success(f"‚úÖ **{len(aires_amelioration)} aires** en am√©lioration (baisse ‚â•{seuil_baisse}%)")
            st.info("üí° Analyser les facteurs de succ√®s pour r√©pliquer dans autres zones")
        
        # Alertes vaccination
        if vaccination_df is not None:
            aires_faible_couv = vaccination_df[vaccination_df['Taux_Vaccination'] < 80]['health_area'].tolist()
            
            if aires_faible_couv:
                st.warning(f"‚ö†Ô∏è **{len(aires_faible_couv)} aires** avec couverture vaccinale <80%")
                st.markdown("**Action recommand√©e:** Campagne de rattrapage vaccinal (AVS)")

# ============================================================
# FOOTER MSF
# ============================================================

st.markdown("---")

if MODULES_AVAILABLE:
    msf_footer()
else:
    st.markdown("""
    <div style="text-align:center; padding:2rem; background-color:#f8f9fa; border-radius:8px;">
        <p style="color:#58595B; margin:0;">D√©velopp√© par <b>Youssoupha MBODJI</b></p>
        <p style="color:#58595B; margin:0;">¬© 2026 - M√©decins Sans Fronti√®res</p>
    </div>
    """, unsafe_allow_html=True)

